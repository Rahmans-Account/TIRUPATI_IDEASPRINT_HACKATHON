{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ LULC Random Forest Classification - Interactive Notebook\n",
    "\n",
    "This notebook provides an interactive way to:\n",
    "- Explore your data\n",
    "- Train and evaluate models\n",
    "- Visualize results\n",
    "- Run predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Import our custom modules\n",
    "from scripts.extract_features import FeatureExtractor\n",
    "from scripts.train_random_forest import LULCTrainer\n",
    "from scripts.run_rf_inference import LULCPredictor\n",
    "from scripts.evaluate_random_forest import LULCEvaluator\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print('âœ“ Imports successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print('Configuration loaded:')\n",
    "print(f\"  Classes: {len(config['classes'])}\")\n",
    "print(f\"  Features: {len(config['features']['bands']) + len(config['features']['indices'])}\")\n",
    "print(f\"  Model: Random Forest with {config['model']['n_estimators']} trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X_train = np.load('../data/training/features.npy')\n",
    "y_train = np.load('../data/training/labels.npy')\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]:,}')\n",
    "print(f'Features per sample: {X_train.shape[1]}')\n",
    "print(f'\\nClass distribution:')\n",
    "\n",
    "for class_id, class_info in config['classes'].items():\n",
    "    count = np.sum(y_train == class_id)\n",
    "    percentage = (count / len(y_train)) * 100\n",
    "    print(f\"  {class_info['name']:15s}: {count:8,} ({percentage:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "class_names = [config['classes'][i]['name'] for i in sorted(config['classes'].keys())]\n",
    "class_counts = [np.sum(y_train == i) for i in range(len(class_names))]\n",
    "\n",
    "# Bar plot\n",
    "ax1.bar(class_names, class_counts, color='steelblue')\n",
    "ax1.set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Samples')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart\n",
    "colors = [tuple(np.array(config['classes'][i]['color'])/255) for i in range(len(class_names))]\n",
    "ax2.pie(class_counts, labels=class_names, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "ax2.set_title('Class Proportions', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics\n",
    "feature_names = config['features']['bands'] + config['features']['indices']\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature_name in enumerate(feature_names):\n",
    "    if i >= len(axes):\n",
    "        break\n",
    "    \n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot histogram for each class\n",
    "    for class_id, class_info in config['classes'].items():\n",
    "        class_data = X_train[y_train == class_id, i]\n",
    "        ax.hist(class_data, bins=50, alpha=0.5, label=class_info['name'])\n",
    "    \n",
    "    ax.set_title(feature_name, fontweight='bold')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    if i == 0:\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(feature_names), len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Feature Distributions by Class', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = LULCTrainer('../config/config.yaml')\n",
    "\n",
    "# Split data\n",
    "X_train_split, X_val, y_train_split, y_val = trainer.prepare_data(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# Train model\n",
    "model = trainer.train_model(X_train_split, y_train_split)\n",
    "\n",
    "print('\\nâœ“ Model training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "report, cm = trainer.evaluate_model(X_val, y_val, save_plots=False)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(importances)), importances[indices])\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "plt.title('Feature Importance', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nTop 5 Most Important Features:')\n",
    "for i in range(min(5, len(importances))):\n",
    "    idx = indices[i]\n",
    "    print(f'  {i+1}. {feature_names[idx]}: {importances[idx]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "trainer.save_model('../models/random_forest/model.pkl')\n",
    "print('âœ“ Model saved successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Inference on New Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize predictor\n",
    "predictor = LULCPredictor('../models/random_forest/model.pkl', '../config/config.yaml')\n",
    "\n",
    "# Run prediction on a test image\n",
    "test_image_path = '../data/raw/sample_image_1.tif'\n",
    "prediction_map = predictor.predict_image(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Original image (RGB composite)\n",
    "with rasterio.open(test_image_path) as src:\n",
    "    r = src.read(3)\n",
    "    g = src.read(2)\n",
    "    b = src.read(1)\n",
    "    rgb = np.dstack([r, g, b])\n",
    "    # Normalize for display\n",
    "    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())\n",
    "\n",
    "axes[0].imshow(rgb)\n",
    "axes[0].set_title('Original Image (RGB)', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Classified map\n",
    "cmap = plt.cm.colors.ListedColormap([tuple(np.array(config['classes'][i]['color'])/255) \n",
    "                                      for i in range(len(config['classes']))])\n",
    "im = axes[1].imshow(prediction_map, cmap=cmap, vmin=0, vmax=4)\n",
    "axes[1].set_title('LULC Classification', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=axes[1], ticks=range(5))\n",
    "cbar.set_ticklabels(class_names)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area statistics\n",
    "pixel_size = 30  # meters (assuming Landsat)\n",
    "pixel_area = (pixel_size ** 2) / 1e6  # kmÂ²\n",
    "\n",
    "print('LULC Area Statistics:')\n",
    "print('=' * 60)\n",
    "\n",
    "total_area = 0\n",
    "for class_id, class_info in config['classes'].items():\n",
    "    count = np.sum(prediction_map == class_id)\n",
    "    area = count * pixel_area\n",
    "    percentage = (count / prediction_map.size) * 100\n",
    "    total_area += area\n",
    "    \n",
    "    print(f\"{class_info['name']:15s}: {area:8.2f} kmÂ² ({percentage:5.2f}%)\")\n",
    "\n",
    "print('=' * 60)\n",
    "print(f\"{'Total':15s}: {total_area:8.2f} kmÂ²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classification to GeoTIFF\n",
    "output_path = '../results/notebook_classification.tif'\n",
    "predictor._save_prediction(prediction_map, output_path, None)\n",
    "\n",
    "print(f'âœ“ Classification saved to {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. âœ… Loading and exploring training data\n",
    "2. âœ… Analyzing feature distributions\n",
    "3. âœ… Training a Random Forest model\n",
    "4. âœ… Evaluating model performance\n",
    "5. âœ… Running inference on new imagery\n",
    "6. âœ… Visualizing results\n",
    "7. âœ… Calculating area statistics\n",
    "\n",
    "Next steps:\n",
    "- Try different hyperparameters\n",
    "- Add more training data\n",
    "- Experiment with feature engineering\n",
    "- Test on different geographic regions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
